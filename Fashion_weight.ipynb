{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c4f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"             #选用GPU序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9da119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from lib import CNN_networks_2\n",
    "num_classes = 10\n",
    "img_row,img_col,channel = 28,28,1\n",
    "threhold=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031737e",
   "metadata": {},
   "source": [
    "## 功能函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4d76fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-------------------------------------------------------------'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''-------------------------------------------------------------'''\n",
    "'''---------------------------功能函数--------------------------'''\n",
    "def read_local_models(models_addr_list):\n",
    "    '''\n",
    "    读取训练好的模型\n",
    "    models_addr_list是模型存储的地址的列表\n",
    "    '''\n",
    "    print('''读取训练好的模型''')\n",
    "    model_list = []\n",
    "    for model_addr in models_addr_list:\n",
    "        model_list.append(load_model(model_addr))\n",
    "    return model_list\n",
    "\n",
    "def choose_models(benign_num, untargeted_num,targeted_num, random_num, models_folder_addr):\n",
    "    '''\n",
    "    根据指定的benign等数量从指定的models_folder_addr中选择client，并返回对应选择的模型的存储地址列表\n",
    "    benign_num:选择的benign client的数量\n",
    "    untargeted_num:选择的untargeted client的数量\n",
    "    targeted_num:选择的targeted client的数量\n",
    "    random_num:选择的random client的数量\n",
    "    models_folder_addr:client模型存储的位置\n",
    "    '''\n",
    "    all_model_addr = list_dir(models_folder_addr)\n",
    "    choosen_model_addr = []\n",
    "    benign_model_addr = []\n",
    "    untargeted_model_addr = []\n",
    "    targeted_model_addr = []\n",
    "    random_model_addr = []\n",
    "    for i in all_model_addr:\n",
    "        if(\"benign_model\" in i):\n",
    "            benign_model_addr.append(i)\n",
    "        elif(\"untargeted_model\" in i):\n",
    "            untargeted_model_addr.append(i)\n",
    "        elif(\"targeted_model\" in i):\n",
    "            targeted_model_addr.append(i)\n",
    "        elif(\"random_model\" in i):\n",
    "            random_model_addr.append(i)\n",
    "        else:\n",
    "            print(\"read addr error\")\n",
    "    choosen_model_addr = benign_model_addr[:benign_num]+untargeted_model_addr[:untargeted_num]+targeted_model_addr[:targeted_num]+random_model_addr[:random_num]\n",
    "    return choosen_model_addr\n",
    "\n",
    "def list_dir(path):\n",
    "    addr_list = []\n",
    "    for addr in os.listdir(path):\n",
    "        if(addr.endswith(\".h5\")):\n",
    "            addr_list.append(path+addr)\n",
    "    return addr_list\n",
    "\n",
    "def round_get_prediction(models,public_images, model_num):\n",
    "    '''\n",
    "    这个函数的作用主要是返回每一轮所有的模型预测结果组成的列表\n",
    "    :param models: teh clients' models\n",
    "    :param test_images: the test images\n",
    "    :param client_num:the number of clients\n",
    "    :return:the precition of all clients for the epoch [client_num]\n",
    "    '''\n",
    "    round_prediction = []#all the clients predictions in this epoch\n",
    "    for k in range(model_num):\n",
    "        round_prediction.append(models[k].model.predict(public_images))\n",
    "    return round_prediction\n",
    "\n",
    "def get_type_accuracy(y_true, y_pred, target_type):\n",
    "    '''\n",
    "    根据输入的预测结果y_pred和真正的标签y_true，对应的标签target_type的precision\n",
    "    '''\n",
    "    right_num = 0\n",
    "    wrong_num = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if(y_pred[i]==target_type):\n",
    "            if(y_true[i]==target_type):\n",
    "                right_num += 1\n",
    "            else:\n",
    "                wrong_num += 1\n",
    "    return right_num/(wrong_num+right_num)\n",
    "'''---------------------------功能函数--------------------------'''\n",
    "'''-------------------------------------------------------------'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b7906",
   "metadata": {},
   "source": [
    "## 数据相关函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea5d0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-------------------------------------------------------------'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''-------------------------------------------------------------'''\n",
    "'''-------------------------数据相关函数------------------------'''\n",
    "def public_dataset_build(round_num, round_data_num, train_data, train_labels, train_answers):\n",
    "    '''收集public的dataset'''\n",
    "    public_set = []#这个是public数据集\n",
    "    public_labels = []#这个是public标签，经过了预处理，拿给CNN网络用\n",
    "    real_public_answers = []#这个是public标签，但没有经过预处理，主要用来最后的效果评估\n",
    "    for i in range(round_num):\n",
    "        public_set.append(train_data[0+i*1000:800+i*1000])\n",
    "        public_labels.append(train_labels[0+i*1000:800+i*1000])\n",
    "        real_public_answers.append(train_answers[0+i*1000:800+i*1000])\n",
    "    return public_set, public_labels, real_public_answers\n",
    "\n",
    "def get_type_list(bait_answers):\n",
    "    all_type = []\n",
    "    for i in range(10):\n",
    "        ind = dict()\n",
    "        temp_type = []\n",
    "        for i, val in enumerate(bait_answers[i]):\n",
    "            ind.setdefault(val, []).append(i)\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                temp_type.append(ind[i])\n",
    "            except:\n",
    "                temp_type.append([])\n",
    "        all_type.append(temp_type)\n",
    "    return all_type\n",
    "\n",
    "        \n",
    "\n",
    "def bait_dataset_build(round_num, round_bait_num, test_data, test_labels, test_answers):\n",
    "    '''制作组成baits的dataset'''\n",
    "    bait_set = []#这个是鱼饵数据集\n",
    "    bait_labels = []#这个是鱼饵标签，经过了预处理，拿给CNN网络用\n",
    "    real_bait_answers = []#这个是鱼饵数据集的真实标签，没有经过预处理，主要用来做最后的byzantine detection\n",
    "    for i in range(round_num):\n",
    "        bait_set.append(test_data[800+i*1000:1000+i*1000])\n",
    "        bait_labels.append(test_labels[800+i*1000:1000+i*1000])\n",
    "        real_bait_answers.append(test_answers[800+i*1000:1000+i*1000])\n",
    "    real_bait_answers_type = get_type_list(real_bait_answers)\n",
    "    return bait_set, bait_labels, real_bait_answers, real_bait_answers_type\n",
    "\n",
    "def data_preprocess(images, labels):\n",
    "    '''\n",
    "    这个函数的作用是将输入的images和labels处理成CNN能够用来训练的格式\n",
    "    '''\n",
    "    images = images.reshape(images.shape[0], img_row, img_col, channel)\n",
    "    images = images.astype(\"float32\")\n",
    "    images /= 255\n",
    "    labels = keras.utils.to_categorical(labels, num_classes)\n",
    "    return images,labels\n",
    "\n",
    "def read_preprocessed_mnist():\n",
    "    '''\n",
    "    读取MNIST数据集并进行预处理\n",
    "    '''\n",
    "    print('''读取MNIST数据集并进行预处理''')\n",
    "    (train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()\n",
    "    train_answers = train_labels\n",
    "    test_answers = test_labels\n",
    "    train_data, train_labels = data_preprocess(train_data,train_labels)\n",
    "    test_data, test_labels = data_preprocess(test_data, test_labels)\n",
    "    return (train_data, train_labels, train_answers),(test_data, test_labels, test_answers)\n",
    "'''-------------------------数据相关函数------------------------'''\n",
    "'''-------------------------------------------------------------'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18dea31",
   "metadata": {},
   "source": [
    "## 声望计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d077b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-------------------------------------------------------------'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''-------------------------------------------------------------'''\n",
    "'''-------------------------计算声望函数------------------------'''\n",
    "def reputation_cal(current_reputation, current_round_num, current_round_bait_answers, current_round_real_labels, current_round_real_labels_type, pro = False):\n",
    "    if(pro):\n",
    "        reputation = reputation_cal_pro(current_reputation, current_round_num, current_round_bait_answers, current_round_real_labels, current_round_real_labels_type)\n",
    "    else:\n",
    "        reputation = reputation_cal_regular(current_reputation, current_round_num, current_round_bait_answers, current_round_real_labels)\n",
    "    return reputation\n",
    "\n",
    "def reputation_cal_regular(current_reputation, current_round_num, current_round_bait_answers, current_round_real_labels):\n",
    "    '''\n",
    "    正常状态下的reputation计算函数\n",
    "    '''\n",
    "    current_round_accuracy = accuracy_score(current_round_real_labels, np.argmax(current_round_bait_answers, axis=1))\n",
    "    reputation = current_round_num*current_reputation + current_round_accuracy\n",
    "    reputation /= (current_round_num+1)\n",
    "    return reputation\n",
    "\n",
    "def reputation_cal_pro(current_reputation, current_round_num, current_round_bait_answers, current_round_real_labels, current_round_real_labels_type):\n",
    "    '''\n",
    "    pro算法下的reputation计算函数\n",
    "    '''\n",
    "    now_reputation = []\n",
    "    for i in range(10):\n",
    "        #print(current_round_real_labels_type[i])\n",
    "        #temp_bait_answers = current_round_bait_answers[current_round_real_labels_type[current_round_num-1][i]]\n",
    "        #temp_real_answers = current_round_real_labels[current_round_real_labels_type[current_round_num-1][i]]\n",
    "        temp_acc = get_type_accuracy(np.argmax(current_round_bait_answers, axis=1), current_round_real_labels,i)\n",
    "        temp_reputation = (current_round_num*current_reputation[i]+temp_acc)/(current_round_num+1)\n",
    "        #temp_reputation = reputation_cal_regular(current_reputation[i], current_round_num, temp_bait_answers, temp_real_answers)\n",
    "        now_reputation.append(temp_reputation)\n",
    "    return now_reputation\n",
    "'''-------------------------计算声望函数------------------------'''\n",
    "'''-------------------------------------------------------------'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e409c82",
   "metadata": {},
   "source": [
    "## 聚合函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1c8306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-------------------------------------------------------------'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''-------------------------------------------------------------'''\n",
    "'''---------------------------聚合函数--------------------------'''\n",
    "def round_aggregate(predictions, round_data_num):\n",
    "    '''\n",
    "    对某一round的所有模型返回的预测进行聚合\n",
    "    '''\n",
    "    client_num = len(predictions)\n",
    "    aggregated_prediction = np.zeros((round_data_num, num_classes))\n",
    "    for k in range(client_num):\n",
    "        aggregated_prediction += predictions[k]\n",
    "    aggregated_prediction = np.argmax(aggregated_prediction, axis=1)\n",
    "    return aggregated_prediction\n",
    "\n",
    "def round_aggregate_reputation_weighted(predictions, round_data_num, reputations):\n",
    "    '''\n",
    "    以reputation为权重，对某一round的所有模型返回的预测进行聚合\n",
    "    '''\n",
    "    client_num = len(predictions)\n",
    "    aggregated_prediction = np.zeros((round_data_num, num_classes))\n",
    "    for k in range(client_num):\n",
    "        aggregated_prediction += predictions[k]*reputations[k]\n",
    "    aggregated_prediction = np.argmax(aggregated_prediction, axis=1)\n",
    "    return aggregated_prediction\n",
    "\n",
    "def round_aggregate_reputation_threhold(predictions, round_data_num, reputations):\n",
    "    '''\n",
    "    以某个threhold作为界限，当低于这个界限的时候，该model被认为byzantine model，这一轮其对应的pre不要\n",
    "    '''\n",
    "    client_num = len(predictions)\n",
    "    aggregated_prediction = np.zeros((round_data_num, num_classes))\n",
    "    for k in range(client_num):\n",
    "        if(reputations[k]>threhold):\n",
    "            aggregated_prediction += predictions[k]\n",
    "    aggregated_prediction = np.argmax(aggregated_prediction, axis=1)\n",
    "    return aggregated_prediction\n",
    "\n",
    "def round_aggregate_reputation_weighted_pro(predictions, round_data_num, reputations):\n",
    "    '''\n",
    "    以reputation为权重，对某一round的所有模型返回的预测进行聚合\n",
    "    '''\n",
    "    client_num = len(predictions)\n",
    "    aggregated_prediction = np.zeros((round_data_num, num_classes))\n",
    "    for k in range(client_num):\n",
    "        aggregated_prediction += predictions[k]*np.array(reputations[k])\n",
    "    aggregated_prediction = np.argmax(aggregated_prediction, axis=1)\n",
    "    return aggregated_prediction\n",
    "\n",
    "'''---------------------------聚合函数--------------------------'''\n",
    "'''-------------------------------------------------------------'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22847e5a",
   "metadata": {},
   "source": [
    "## 模拟服务器训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "755d61f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-----------------------------------------------------------------------'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''-----------------------------------------------------------------------'''\n",
    "'''-------------------------模拟服务器训练模型函数------------------------'''\n",
    "def get_all_acc(server_set, all_answers):\n",
    "    '''\n",
    "    模拟server模型获得aggregated-server_set后的训练过程\n",
    "    server_set:获得的aggregated的所有轮次的public_dataset\n",
    "    all_answers:aggregated得到的server_set对应的标签\n",
    "    '''\n",
    "    (train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()\n",
    "    test_answers = test_labels\n",
    "    test_data, test_labels = data_preprocess(test_data, test_labels)\n",
    "    all_acc = []\n",
    "\n",
    "    model = CNN_networks_2.Res_Build()\n",
    "    for i in range(len(server_set)):\n",
    "        model = CNN_networks_2.ResNet_train(model, server_set[i], all_answers[i], test_data[8000:10000], test_labels[8000:10000])\n",
    "        test_prediction = model.predict(test_data[8000:10000])\n",
    "        test_prediction = np.argmax(test_prediction, axis=1)\n",
    "        all_acc.append(accuracy_score(test_answers[8000:10000], test_prediction))\n",
    "    return all_acc\n",
    "\n",
    "\n",
    "def retrain_model(fl_server, train_images, train_labels, test_images, test_labels):\n",
    "    history = fl_server.model.fit(train_images, train_labels, batch_size=50, epochs=10, verbose=1, \n",
    "                        validation_data=(test_images, test_labels))\n",
    "    score = fl_server.model.evaluate(test_images, test_labels, verbose=0)\n",
    "    return self.model\n",
    "'''-------------------------模拟服务器训练模型函数------------------------'''\n",
    "'''-----------------------------------------------------------------------'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f1d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_aggregate(round_num, models_addr_list, FL_weight, FL_threhold, FL_pro=False, round_public_size=800, round_bait_size=200):\n",
    "    #获取处理过的数据集\n",
    "    (train_data, train_labels, train_answers),(test_data, test_labels, test_answers)=read_preprocessed_mnist()\n",
    "    #获取存储的已训练好的local模型\n",
    "    model_list = read_local_models(models_addr_list)\n",
    "\n",
    "    '''读取数据，public的数据是server用来发给client的模型打标签的数据;bait的数据是server用来发给client的模型进行钓鱼的数据'''\n",
    "    public_set, public_labels, real_public_answers = public_dataset_build(round_num, round_public_size, test_data, test_labels, test_answers)\n",
    "    bait_set, bait_labels, real_bait_answers, real_bait_answers_type = bait_dataset_build(round_num, round_bait_size, test_data, test_labels, test_answers)\n",
    "\n",
    "    \n",
    "    '''used数据是对public数据和bait数据进行组合后的数据'''\n",
    "    used_set = []\n",
    "    used_labels = []\n",
    "    real_used_answers = []\n",
    "    for m in range(round_num):\n",
    "        used_set.append(np.vstack((bait_set[m],public_set[m])))\n",
    "        used_labels.append(np.vstack((bait_labels[m],public_labels[m])))\n",
    "        real_used_answers.append(np.hstack((real_bait_answers[m],real_public_answers[m])))\n",
    "    \n",
    "    \n",
    "    print('''初始化声望机制的各项指标''')\n",
    "    if(FL_pro==False):\n",
    "        round_reputations = [0.5]*len(models_addr_list)#round_reputations指的是当前的round的reputations\n",
    "        all_reputations = []#all_reputations指的是所有round的round_reputations的集合\n",
    "        all_reputations.append(round_reputations)\n",
    "    elif(FL_pro==True):\n",
    "        all_reputations = []\n",
    "        client_reputations = [0.5]*10\n",
    "        round_reputations = []\n",
    "        for j in range(len(models_addr_list)):\n",
    "            round_reputations.append(client_reputations)\n",
    "        all_reputations.append(round_reputations)\n",
    "\n",
    "    \n",
    "    print('''开始进行集成联邦学习''')\n",
    "    all_used_answers = []\n",
    "    all_aggregated_answers = []\n",
    "    for i in range(round_num):\n",
    "        round_used_answers = []\n",
    "        round_reputations = []\n",
    "        #进行每一轮的学习\n",
    "        for k in range(len(model_list)):\n",
    "            round_used_answers.append(model_list[k].predict(used_set[i]))\n",
    "            #当前轮第k个client的reputation并存放到当前轮的round_reputations中\n",
    "            round_reputations.append(reputation_cal(all_reputations[i][k],i+1, round_used_answers[k][:round_bait_size], real_bait_answers[i], real_bait_answers_type, FL_pro))\n",
    "            #去掉当前轮次预测结果中的bait_set部分的预测（没用）\n",
    "            round_used_answers[k] = round_used_answers[k][round_bait_size:round_bait_size+round_public_size]\n",
    "        all_reputations.append(round_reputations)\n",
    "        all_used_answers.append(round_used_answers)\n",
    "        \n",
    "        '''根据输入的参数选择聚合算法'''\n",
    "        if(FL_weight==1):\n",
    "            round_aggregated_answers = round_aggregate_reputation_weighted(round_used_answers,round_public_size, round_reputations)\n",
    "        elif(FL_threhold==1):\n",
    "            round_aggregated_answers = round_aggregate_reputation_threhold(round_used_answers,round_public_size, round_reputations)\n",
    "        elif(FL_pro==True):\n",
    "            round_aggregated_answers = round_aggregate_reputation_weighted_pro(round_used_answers,round_public_size, round_reputations)\n",
    "        else:\n",
    "            round_aggregated_answers = round_aggregate(round_used_answers,round_public_size)\n",
    "        all_aggregated_answers.append(round_aggregated_answers)\n",
    "    return all_reputations, all_aggregated_answers, public_set, public_labels, real_public_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f11454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50, 0, 0, 0], [50, 0, 0, 0]]\n",
      "读取MNIST数据集并进行预处理\n",
      "读取训练好的模型\n",
      "初始化声望机制的各项指标\n",
      "开始进行集成联邦学习\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "imbalance_value_list = [0.2]#不平衡度的选择列表\n",
    "byzantine_portion_list = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]#byzantine占所有client比的列表\n",
    "threhold_weight_list = [ [0,0,False], [1,0,False] ]#参数选择方式的列表\n",
    "for i in imbalance_value_list:\n",
    "    for b in byzantine_portion_list:\n",
    "        b_v_list = []\n",
    "        b_num = int(50*b)\n",
    "        b_v_list.append([50-b_num,b_num,0,0])\n",
    "        b_v_list.append([50-b_num,0,0,b_num])\n",
    "        print(b_v_list) \n",
    "        all_all_acc = []\n",
    "        all_rep=[]\n",
    "        for byzantine_num_group in b_v_list:\n",
    "            for parameter_group in threhold_weight_list:\n",
    "                reputations, all_answers, server_set, server_labels, server_answers = all_aggregate(10,choose_models(byzantine_num_group[0],byzantine_num_group[1],byzantine_num_group[2],byzantine_num_group[3],\"../fashion_mnist_models/imbalance_\"+str(i)+\"/\"),parameter_group[0], parameter_group[1],parameter_group[2])\n",
    "                for answer_num in range(len(all_answers)):\n",
    "                    all_answers[answer_num] = keras.utils.to_categorical(all_answers[answer_num], 10)\n",
    "                all_acc = get_all_acc(server_set, all_answers)\n",
    "                all_all_acc.append(all_acc)\n",
    "            all_rep.append(reputations)\n",
    "                \n",
    "        untargeted_rep = pd.DataFrame(all_rep[0])\n",
    "        random_rep = pd.DataFrame(all_rep[1])\n",
    "        untargeted_rep_csv_name = \"./rep_records/weight/untargeted_i_\"+str(i)+\"_b_\"+str(b)+\".csv\"\n",
    "        random_rep_csv_name = \"./rep_records/weight/random_i_\"+str(i)+\"_b_\"+str(b)+\".csv\"\n",
    "        untargeted_rep.to_csv(untargeted_rep_csv_name)\n",
    "        random_rep.to_csv(random_rep_csv_name)\n",
    "        \n",
    "        all_acc_data = pd.DataFrame(all_all_acc)\n",
    "        acc_csv_name = \"./acc_records/weight/i_\"+str(i)+\"_b_\"+str(b)+\".csv\"\n",
    "        print(acc_csv_name)\n",
    "        all_acc_data.to_csv(acc_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e23fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "imbalance_value_list = [0.1,0.2,0.5,0.6,0.7,0.8,0.9]#不平衡度的选择列表\n",
    "byzantine_portion_list = [0.5]#byzantine占所有client比的列表\n",
    "threhold_weight_list = [ [0,0,False], [1,0,False] ]#参数选择方式的列表\n",
    "for i in imbalance_value_list:\n",
    "    for b in byzantine_portion_list:\n",
    "        b_v_list = []\n",
    "        b_num = int(50*b)\n",
    "        b_v_list.append([50-b_num,b_num,0,0])\n",
    "        b_v_list.append([50-b_num,0,0,b_num])\n",
    "        print(b_v_list) \n",
    "        all_all_acc = []\n",
    "        all_rep=[]\n",
    "        for byzantine_num_group in b_v_list:\n",
    "            for parameter_group in threhold_weight_list:\n",
    "                reputations, all_answers, server_set, server_labels, server_answers = all_aggregate(10,choose_models(byzantine_num_group[0],byzantine_num_group[1],byzantine_num_group[2],byzantine_num_group[3],\"../fashion_mnist_models/imbalance_\"+str(i)+\"/\"),parameter_group[0], parameter_group[1],parameter_group[2])\n",
    "                for answer_num in range(len(all_answers)):\n",
    "                    all_answers[answer_num] = keras.utils.to_categorical(all_answers[answer_num], 10)\n",
    "                all_acc = get_all_acc(server_set, all_answers)\n",
    "                all_all_acc.append(all_acc)\n",
    "            all_rep.append(reputations)\n",
    "                \n",
    "        untargeted_rep = pd.DataFrame(all_rep[0])\n",
    "        random_rep = pd.DataFrame(all_rep[1])\n",
    "        untargeted_rep_csv_name = \"./rep_records/weight/untargeted_i_\"+str(i)+\"_b_\"+str(b)+\".csv\"\n",
    "        random_rep_csv_name = \"./rep_records/weight/random_i_\"+str(i)+\"_b_\"+str(b)+\".csv\"\n",
    "        untargeted_rep.to_csv(untargeted_rep_csv_name)\n",
    "        random_rep.to_csv(random_rep_csv_name)\n",
    "        \n",
    "        all_acc_data = pd.DataFrame(all_all_acc)\n",
    "        acc_csv_name = \"./acc_records/weight/i_\"+str(i)+\"_b_\"+str(b)+\".csv\"\n",
    "        print(acc_csv_name)\n",
    "        all_acc_data.to_csv(acc_csv_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
